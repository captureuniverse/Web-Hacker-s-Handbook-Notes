MAPPING THE APPLICATION

	ENUMERATING CONTENT AND FUNCTIONALITY OF WEBSITE

		WEB SPIDERING

		1. Configure your browser to use either Burp or WebScarab as a local proxy between your browser and webserver.

		2. Browse the entire application normally attempting to visit every link/URL you discover, submitting every form, and proceeding through all multi step functions to completion.

			Note: Try user-directing spidering instead of automatic spidering so that no URL is left behind.

		3. Try browsing JS enabled and JS disabled as well as cookies enables and cookies disabled. Many applications can handle various browser configurations, and you may reach different content and code paths within the app.

		4. Review the site map generated by spider tool and identify any application content or functions that you did not browse manually.

		5. Configure your spider to add maliscious and out of scope URLs in Out Of Scope and the URLs which you have already accessed, send them also into Out of Scope so that  you won't enumerate content from starting point.

		Note: THe site map generated by the proxy/spider tool contains a wealth of information about the target application, which will be useful later in identifying
		attack surfaces exposed by the app.


		DISCOVERING HIDDEN CONTENT

		Note: Spidering is done on the privilege level which hacker have whereas if website have prvileges levels(like anonymous, registered and administration), then spider may miss links of other privileges.

		1. Backup copies of live files, enabling you to review the page source for vulnerabilities that can be exploited on the live page.

		2.Backup archives that contain a full snapshot of files within (or outside) the web root, enabling you to identify all content and functionality within the app.

		3. New functionality that has been deployed to server for testing but not yet linked from the main application.

		4. Default application functionality in an off-the-shelf application that has been superficially hidden form the user but is still present on the server.

		5. Old version of files that have not been removed from the server. In the case of dynamic pages, these may contain vulnerabilities that have been fixed in the current version but that can still be exploited in the old version.

		6. Configuration and include files containing sensitive data such as database credentials.

		7. Source files from which the live application's functionality has been compiled.

		8.Comments in source code may contain information such as usernames and passwords but that are more likely provide the information about the state of the application. Some important functions are also commented out sometimes.

		9.Log files that may contain sensitive information such as valid usernames, session tokens, URLs visited and actions performed.


		BRUTEFORCING HIDDEN CONTENT DIRECTORIES

		1. Make a list of all the directories which may give 200 or 302 status codes or use SecLists available on github which have a list of all the directories already present.

		2. Automate attack on all the directories using Burp intruder or using wfuzz(Both tools are great).

		3. Capture the responses received from the server, and manually review them to identify valid resources.

		Note: Perform same steps recursively as a new content is discovered.

		Note: Dirbuster or dirb and BurpSuite Pro Content Discovery feature can also be used for automatic enumeration of more and more files that may contain some information.

		Note: Review each and every source code of HTML and JS, they could contain some tags hidden or some buttons disabled or some important functions which you can exploit.



		COMBINING BOTH USER-DIRECTED BROWSING AND BRUTEFORCING

		1. Review all the results of your spidering and directory bruteforcing.

		2. Review these lists to identify any naming schemes in use. For example, if there are pages called AddDocument.jsp and ViewDocument.jsp, there may also pages like EditDocument.jsp, etc. Make a list of $$Document.jsp and run an intruder attack.

		3. Comapnie's finanicial files could also be present there like AnnualReport2009.pdf,  then try enumerating AnnualReport2020.pdf and if you got access then you have their financial files before company have announced it publicly.

		4. Add file extension list such as txt, bak, src, inc, etc. which may uncover the source to backup versions of live pages.

		5. Search for temporary files like .DS_Store file, which contains directory under file.php~1 which is a temporary file created when file.php is edited.


		Note: Perform each exercise recursively.

		USE OF PUBLIC INFORMATION

		1. Use different search engines and web archives(like WayBack Machine) to discover what content they indexed

		2. site: www.wahh-target.com returns every resource within the target site that Google has reference to.

		3. site: www.wahh-target.com login returns all the pages containing expression login.

		4. link: www.wahh-target.com returns all the pages on other websites and applications that contain a link to the target.

		5. related: www.wahh-target.com returns pages that are similar to the target.


		5. Perform each search not only in default WebSection of Google, but also in Groups and News, which may contain different results.

		Note: Voew the cached version of interesting pages, including any content that is no longer present in the actual application. In some cases search engine caches contain resources that cannot be directly accesses in the application without authentication or payment.

		TOOL FOR FINDING DIRECTORY WHICH YOU CAN'T FIND EVEN WITH SPIDERING OR BRUTEFORCING DIRECTORIES

		1. Wikto
		2. Nikto

		DISCOVERING HIDDEN PARAMETERS

		For example, an application may behave differently if the parameter debug=true is added to the query string of any URL. It might turn off certain input validation checks, allow the user to bypass certain access controls, or display verbose debug informa-tion in its response.

		Other parameters like debug, test, hide, source, etc. and common values (true, yes, on, 1, etc.). Make large number of requests using these parameters in URL to bypass input validation checks

			Use Burp Intruder to do that by making  a list of all these parameters.

		Monitor all responses received to identify any anomalies that many indicate that the added parameter has had an effect on the application's processing.
		
		FINGERPRINT THE WEB SERVER
		http recon or httprint tool

		This tool fingerprints webservers present on the website and give you the percentage of which server could be present.

		FILE EXTENSIONS

		asp — Microsoft Active Server Pages
		aspx — Microsoft ASP.NET
		jsp : Java Server Pages
		cfm: COld Fusion
		php: The PHP Language
		d2w: WebSphere
		pl: The Perl Language
		py: The Python Language
		nsf or ntf: Lotus Domino

		Another common fingerprint to be aware of are URLs that look like this:
		https://wahh-app/news/0,,2-421206,00.html

			The comma-separated numbers toward the end of the URL are usually generated by the Vignette content management platform.

		DIRECTORY NAMES
		
		servlet- Java Servlets
		pls- Pracle Application Server PL/SQL Gateway
		cfdocs or cfide- Cold Fusion
		SilverStream- The Silver Stram Web Server
		WebObjects or {function}.woa- Apple Web Objects
		rails- Ruby on Rails

		SESSION TOKENS

		JSESSIONID- The Java Platform
		APSSESSIONID- Microsoft IIS Server
		ASP .NET_SessionId- Microsoft ASP.NET
		CFID/CFTOKEN- Cold Fusion
		PHPSESSID- PHP



		MAPPING THE APPLICATION

		Review all technologies, functionalities and vlnerabilities.(Read the chapter again)